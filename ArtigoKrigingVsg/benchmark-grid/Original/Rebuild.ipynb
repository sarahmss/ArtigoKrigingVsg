{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def benchmark(x1, x2):\n",
    "    return (    (1.3356 * (1.5 * (1 - x1))) \n",
    "                + (np.exp((2 * x1) - 1) * np.sin((3 * np.pi) * ((x1 - 0.6) ** 2)))\n",
    "                + (np.exp(3 * (x2 - 0.5)) * np.sin((4 * np.pi) * ((x2 - 0.9) ** 2)))\n",
    "            )\n",
    "\n",
    "def getData(grid):\n",
    "    x1 = np.linspace(0, 1, grid)\n",
    "    x2 = np.linspace(0, 1, grid)\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "    f_x1_x2 = benchmark(x1, x2)\n",
    "    data = {'x1': x1.flatten(), 'x2': x2.flatten(), 'f(x1,x2)': f_x1_x2.flatten()}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_1000 = getData(32)\n",
    "df_test = pd.read_excel(\"../Kriging-data.xlsx\", sheet_name=\"Test\")\n",
    "df_training = pd.read_excel(\"../Kriging-data.xlsx\", sheet_name=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "out_scaler = StandardScaler()\n",
    "\n",
    "def show_norm(df, label=\"data\", plot=False):\n",
    "    df_norm = pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "    df_denorm = pd.DataFrame(scaler.inverse_transform(df_norm), columns=df_norm.columns)\n",
    "\n",
    "    if (plot):\n",
    "        df.plot(title=f\"{label}: Original data\")\n",
    "        df_norm.plot(title=f\"{label}: Normalized data\")\n",
    "        df_denorm.plot(title=f\"{label}: Denormalized data\")\n",
    "    return (df_norm)\n",
    "\n",
    "\n",
    "def test_out_scaler(df):\n",
    "    out = df[\"f(x1,x2)\"].values.reshape(-1, 1)  \n",
    "    plt.plot(out, label='Original')\n",
    "    out_scaler.fit(out)\n",
    "    norm = out_scaler.transform(out)\n",
    "    plt.plot(norm, label='Normalizado')\n",
    "    plt.plot(out_scaler.inverse_transform(norm), label='desnormalizado')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "scaler.fit(df_training)\n",
    "test_out_scaler(df_training)\n",
    "\n",
    "df_training_norm = show_norm(df_training, \"Training\")\n",
    "df_1000_norm = show_norm(df_1000)\n",
    "df_test_norm = show_norm(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"./content\")\n",
    "\n",
    "lm_dir = \"tf-levenberg-marquardt\"\n",
    "if not os.path.exists(lm_dir):\n",
    "  !git clone https://github.com/fabiodimarco/$lm_dir\n",
    "\n",
    "os.chdir(lm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    _input = np.vstack([df['x1'], df['x2']]).T\n",
    "    _output = np.array(df['f(x1,x2)'])\n",
    "    return (_input, _output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "import levenberg_marquardt as lm\n",
    "\n",
    "# layers, neurons\n",
    "class ShuffleArchitecture:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, act_h, act_o, param_reg):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.act_h = act_h\n",
    "        self.act_o = act_o\n",
    "        self.regularizer = regularizers.L2(param_reg)\n",
    "        self.initializer = initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=np.random.randint(1, 10000))\n",
    "\n",
    "    def compute_k(self):\n",
    "        total_parameters = 0\n",
    "        for layer in self.model.layers:\n",
    "            weights = layer.get_weights()\n",
    "            if len(weights) > 0:  \n",
    "                for w in weights:\n",
    "                    total_parameters += np.prod(w.shape)\n",
    "        return total_parameters\n",
    "        \n",
    "    def set_architecture(self):\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Dense(self.hidden_sizes[0],\n",
    "                        input_shape=(self.input_size,),\n",
    "                        activation=self.act_h,\n",
    "                        kernel_regularizer=self.regularizer,\n",
    "                        kernel_initializer=self.initializer,                        \n",
    "                        ))  # input layer\n",
    "\n",
    "        for size in self.hidden_sizes[1:]:  # hidden layers\n",
    "            self.model.add(tf.keras.layers.Dense(size,\n",
    "                            activation=self.act_h,\n",
    "                            kernel_regularizer=self.regularizer,\n",
    "                            kernel_initializer=self.initializer,  \n",
    "                        ))\n",
    "\n",
    "        self.model.add(tf.keras.layers.Dense(self.output_size,\n",
    "                        activation=self.act_o,\n",
    "                        kernel_regularizer=self.regularizer,\n",
    "                        kernel_initializer=self.initializer,  \n",
    "                        ))  # output layer\n",
    "\n",
    "    def create_model(self, _learning_rate):\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=_learning_rate),\n",
    "            loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "        self.lm_model = lm.ModelWrapper(\n",
    "            tf.keras.models.clone_model(self.model))\n",
    "\n",
    "        self.lm_model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=_learning_rate),\n",
    "            loss=lm.MeanSquaredError())\n",
    "        return(self.lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, root_mean_squared_error, mean_absolute_percentage_error \n",
    "\n",
    "class Rebuild:\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_excel(f\"../../results/better_results.xlsx\")\n",
    "        self.input_1000, self.output_1000 = split_df(df_1000_norm)\n",
    "\n",
    "    def LoadModelWeights(self, model, fileName):        \n",
    "        path = f\"../models/{fileName}.keras\"\n",
    "        if (os.path.exists(path)):\n",
    "            model.load_weights(path)\n",
    "            return (True)\n",
    "        return (False)\n",
    "    \n",
    "\n",
    "    def setArchitecture(self, _hidden_sizes, _pg, _lr):\n",
    "        shuffler = ShuffleArchitecture(input_size  = 2,\n",
    "                                        hidden_sizes = _hidden_sizes,\n",
    "                                        output_size = 1,\n",
    "                                        act_h = 'tanh',\n",
    "                                        act_o = 'linear',\n",
    "                                        param_reg=_pg)\n",
    "        shuffler.set_architecture()\n",
    "        self.k = shuffler.compute_k()\n",
    "        return(shuffler.create_model(_lr))            \n",
    "\n",
    "    def getArchitecture(self, architecture):\n",
    "        hidden_size = [int(x) for x in architecture.split(\"[\")[1].split(\"]\")[0].split(\", \")]\n",
    "        regularizer = float(architecture.split(\"regularizer=\")[1].split(\",\")[0])\n",
    "        learning_rate = float(architecture.split(\"learning_rate=\")[1])\n",
    "        return hidden_size, regularizer, learning_rate\n",
    "\n",
    "    def PlotNewDataResults(self, df, label):\n",
    "        columns = df.columns[2:]\n",
    "        for column in columns:\n",
    "            plt.scatter(df.index, df[column], label=column)\n",
    "        plt.xlabel('Amostra')\n",
    "        plt.ylabel('Valores Preditos pela rede')\n",
    "        plt.title(f'Gráfico de Dispersão para {label}')\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def ComputeOut(self):\n",
    "        pred = self.lm_model.predict(self.input_1000).flatten()\n",
    "        pred_denorm = out_scaler.inverse_transform(pred.reshape(-1, 1))\n",
    "        orig_denorm = out_scaler.inverse_transform(self.output_1000.reshape(-1, 1))\n",
    "        return (pred_denorm, orig_denorm)\n",
    "\n",
    "    def ComputeMetricsForNewData(self, predicted, original):\n",
    "        return ({\n",
    "                          'r2': r2_score(original, predicted),\n",
    "                          'mse': mean_squared_error(original, predicted),\n",
    "                          'mape': mean_absolute_percentage_error(original, predicted),\n",
    "                          'rmse': root_mean_squared_error(original, predicted),\n",
    "                          })\n",
    "    \n",
    "    def SaveResults(self, metrics, outs):\n",
    "        with pd.ExcelWriter(f'../../results/results.xlsx') as writer:\n",
    "            outs.to_excel(writer, sheet_name=\"Output\", index=False)\n",
    "            metrics.to_excel(writer, sheet_name=\"metrics\", index=True)\n",
    "        display(outs)\n",
    "        display(metrics)\n",
    "\n",
    "        \n",
    "    def TestNewData(self):\n",
    "        metrics = {}\n",
    "        df = df_1000\n",
    "        for file_model, architecture in zip(self.df[\"model\"], self.df[\"Architecture\"]):\n",
    "            hidden_size, regularizer, learning_rate = self.getArchitecture(architecture)\n",
    "            self.lm_model = self.setArchitecture(hidden_size, regularizer, learning_rate)\n",
    "            if (self.LoadModelWeights(self.lm_model, file_model) == True):\n",
    "                predicted, original = self.ComputeOut()\n",
    "                df[file_model] = predicted\n",
    "                metrics[file_model] = self.ComputeMetricsForNewData(predicted, original)\n",
    "        self.SaveResults(pd.DataFrame(metrics), df)\n",
    "        # self.PlotNewDataResults(df, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rebuilder = Rebuild()\n",
    "Rebuilder.TestNewData()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
